# -*- coding: utf-8 -*-
"""
Created on Tue Apr 18 14:08:51 2017

@author: cglynn

cluster_tweets(int)
Cluster tweets using KMeans, option 1, or Agglomerative Clustering, option 2.
Creates a feature vector from tweet text and query text.  Feature vector contains
one feature for every query term.  For each query term saves the frequency of that
query term.

Ouputs the clusters into files clusterVideoX.txt where X is the cluster number.

"""
from sklearn.cluster import KMeans, AgglomerativeClustering
import json
import glob, os

query_terms_File = 'query.data'
retrieved_tweets = 'cluster_tweets.txt'

#Cluster Type 1 = kmeans, 2= Agglomerative
def cluster_tweets(clusterType):
    #Remove previously generated files
    filelist=glob.glob('clusterVideo*.txt') 
    for file in filelist: 
        os.remove(file) 
        
    #Read in Query Terms in dictionary
    vocab = dict()
    queryTerms = []
    with open(query_terms_File) as file:
        queryFile = file.readlines()
        queryTerms = json.loads(queryFile[0])
    clusters = len(queryTerms)
    for term in queryTerms:
        terms = term.split()
        for word in terms:
            word = word.lower()
            vocab[word] = 1
    
    #Read Tweets in
    tweets = []
    for line in open(retrieved_tweets).readlines():
        tweets.append(json.loads(line))    
    
    # Generate an id (starting from 0) for each term in vocab
    vocab = {term: idx for idx, (term, freq) in enumerate(vocab.items())}
    
    # Generate X
    X = []
    for tweet_id, tweet_text in tweets:
        x = [0] * len(vocab)
        terms = [term for term in tweet_text.split() if len(term) > 2]
        for term in terms:
            if vocab.has_key(term):
                x[vocab[term]] += 1
        X.append(x)
    
    if clusterType == 1:
        km = KMeans(n_clusters = clusters, n_init = 100) # try 100 different initial centroids
    else:
        km =     AgglomerativeClustering(n_clusters = clusters, linkage='ward')
        
    km.fit(X)
    
    cluster_stat = dict()
    # Print tweets that belong to clusters
    for idx, cls in enumerate(km.labels_):
        if cluster_stat.has_key(cls):
            cluster_stat[cls] += 1
        else:
            cluster_stat[cls] = 1
        open('clusterVideo-{0}.txt'.format(cls), 'a').write(json.dumps(tweets[idx][1]) + '\r\n')
    
#    print 'basic information about the clusters that are generated by the k-means clustering algorithm: \r\n'
#    print 'total number of clusters: {0}\r\n'.format(len(cluster_stat))
    clusterSize = []
#    for cls, count in cluster_stat.items():
#        print 'cluster {0} has {1} tweets'.format(cls, count)
    for cls, count in cluster_stat.items():
        clusterSize.append(count)
#    print clusterSize.index(max(clusterSize))
    return clusterSize.index(max(clusterSize))
    
    
if __name__ == '__main__':
    cluster_tweets(1)
